{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York Fare Classification\n",
    "\n",
    "Download New York Fare dataset at Google Classroom\n",
    "\n",
    "Objectives \n",
    "- learn embeddings (done!)\n",
    "- learn dropout (done! yay!)\n",
    "- serve as another case study\n",
    "\n",
    "Embedding\n",
    "- a very powerful concept\n",
    "- replaces label-encoding and one-hot encoding\n",
    "  - label-encoding:  turns category into numbers\n",
    "  - one-hot encodings: turns category into cols\n",
    "- In neural network, we don't have to....\n",
    "  - we instead assign a vector of numbers for each category\n",
    "  - Let's say I have 1000 samples, one col with two categories (morning, afternoon)\n",
    "    - SHAPE: (1000, 1)\n",
    "  - But for neural network, we can first create random vectors representing each category\n",
    "    - morning:   [1, 5, 0.3, 2, 5]\n",
    "    - afternoon: [4, 3, 0.2, 1, 0.9]\n",
    "    - SHAPE: (1000, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stuffs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/NYCTaxiFares.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "#1. convert UTC to New York time....\n",
    "#2. extract hours, am/pm, day as features\n",
    "#3. fare_class is our y/target/label\n",
    "#4. engineer some distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.666667\n",
       "1    0.333333\n",
       "Name: fare_class, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check class imbalance of data\n",
    "#the first thing you must do in any dataset\n",
    "df['fare_class'].value_counts(normalize=True)\n",
    "#0 means less than 10 dollars\n",
    "#1 means greater than equal to 10 dollars\n",
    "#upsampling - SMOTE\n",
    "#downsampling - I don't remember\n",
    "#I think there is a library imblearn - take a look\n",
    "#remember, if you use cross-validation, do it during cross-validation\n",
    "#basically, no data leakage........"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "We are lazy today....so skip...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "- create the distance column for us\n",
    "\n",
    "### Calculate the distance traveled\n",
    "The <a href='https://en.wikipedia.org/wiki/Haversine_formula'>haversine formula</a> calculates the distance on a sphere between two sets of GPS coordinates.<br>\n",
    "Here we assign latitude values with $\\varphi$ (phi) and longitude with $\\lambda$ (lambda).\n",
    "\n",
    "The distance formula works out to\n",
    "\n",
    "${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2})\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{align} r&: \\textrm {radius of the sphere (Earth's radius averages 6371 km)}\\\\\n",
    "\\varphi_1, \\varphi_2&: \\textrm {latitudes of point 1 and point 2}\\\\\n",
    "\\lambda_1, \\lambda_2&: \\textrm {longitudes of point 1 and point 2}\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi    = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # in kilometers\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column called hav_dis inside df using this function\n",
    "df['hav_dis'] = haversine_distance(df, 'pickup_latitude', \n",
    "                                       'pickup_longitude',\n",
    "                                       'dropoff_latitude', \n",
    "                                       'dropoff_longitude',)\n",
    "\n",
    "#don't put correlated features into the model\n",
    "#all features are assumed to be uncorrelated\n",
    "#ex:  height in inches and height in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean          3.322160\n",
       "std           3.337004\n",
       "min           0.010208\n",
       "25%           1.316428\n",
       "50%           2.237084\n",
       "75%           4.034564\n",
       "max          28.846365\n",
       "Name: hav_dis, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hav_dis'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='fare_class', ylabel='hav_dis'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#a little bit\n",
    "#bivariate analysis between hav_dis and fare_class\n",
    "import seaborn as sns\n",
    "sns.boxplot(x = df.fare_class, y = df.hav_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction\n",
    "\n",
    "1. convert UTC to New York time....\n",
    "2. extract hours, am/pm, day as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-04-19 08:17:56 UTC'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pickup_datetime'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the time difference between UTC and New York....\n",
    "df['new_york_time'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hour  - df['new_york_time'].dt.hour\n",
    "#day   - df['new_york_time'].dt.strftime(\"%a\")\n",
    "#am/pm - np.where(hour < 12, 'am', 'pm')\n",
    "#np.where(condition, if true, if false)\n",
    "df['hour'] = df['new_york_time'].dt.hour\n",
    "df['day']  = df['new_york_time'].dt.strftime(\"%a\")\n",
    "df['ampm'] = np.where(df['hour'] < 12, 'am', 'pm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['am', 'pm'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ampm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help me write a simple assert function\n",
    "#there should be no more than 24 hours\n",
    "assert len(df['hour'].unique()) <= 24, \"More than 24 hours\"\n",
    "assert df['hour'].min() == 0, \"Some negative hours!\"\n",
    "assert df['hour'].max() == 23, \"Not a normal time system~\"\n",
    "\n",
    "#there should be no more than 7 days\n",
    "assert len(df['day'].unique()) == 7, \"Something not Mon-Sun\"\n",
    "\n",
    "#there should be only am and pm\n",
    "assert (df['ampm'].unique() == np.array(['am', 'pm'])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Categorify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns name\n",
    "cat_cols  = ['hour', 'ampm', 'day']\n",
    "cont_cols = ['pickup_latitude', 'pickup_longitude', \n",
    "             'dropoff_latitude', 'dropoff_longitude',\n",
    "             'passenger_count', 'hav_dis'] \n",
    "y         = ['fare_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is a dtype called category\n",
    "#which gonna neatly turns our data into integers....\n",
    "#basically it's like label encoding, but much more\n",
    "#why we need to turn it into category first\n",
    "#because, the embedding is like for 0, 1, 2\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ampm'].cat.categories\n",
    "#df['ampm'].cat.codes\n",
    "#df['ampm'].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime      0\n",
       "fare_amount          0\n",
       "fare_class           0\n",
       "pickup_longitude     0\n",
       "pickup_latitude      0\n",
       "dropoff_longitude    0\n",
       "dropoff_latitude     0\n",
       "passenger_count      0\n",
       "hav_dis              0\n",
       "new_york_time        0\n",
       "hour                 0\n",
       "day                  0\n",
       "ampm                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #let me guess, no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack the hours, ampm, and day as one vector\n",
    "\n",
    "hr   = df['hour'].cat.codes.values #[vectors of hours, e.g., 0, 4, 2]\n",
    "ampm = df['ampm'].cat.codes.values\n",
    "day  = df['day'].cat.codes.values\n",
    "\n",
    "time = np.stack([hr, ampm, day], 1)\n",
    "\n",
    "time[:5]\n",
    "\n",
    "time.shape  #(120000 samples, 3 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert this numpy into tensor\n",
    "time = torch.tensor(time, dtype=torch.int64)\n",
    "time[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickup_latitude',\n",
       " 'pickup_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'dropoff_longitude',\n",
       " 'passenger_count',\n",
       " 'hav_dis']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarly, we want to stack them into a vector of size 6\n",
    "lat1  = df['pickup_latitude'].values  #.values give you the numpy vector\n",
    "lat2  = df['dropoff_latitude'].values\n",
    "long1 = df['pickup_longitude'].values\n",
    "long2 = df['dropoff_longitude'].values\n",
    "ps_count = df['passenger_count'].values\n",
    "hav_dis  = df['hav_dis'].values\n",
    "#use list comprehension\n",
    "#[df[col].values for col in cont_cols]\n",
    "\n",
    "conts = np.stack([lat1, lat2, long1, long2, ps_count, hav_dis], 1)\n",
    "\n",
    "#turn this into tensor...\n",
    "conts = torch.tensor(conts, dtype=torch.float32)\n",
    "\n",
    "conts[:4]\n",
    "conts.shape  #(120000, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finally, we need the y, to be in tensor\n",
    "y = torch.tensor(df[y].values).flatten()  #reshape(-1)\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Determine the embedding size\n",
    "\n",
    "- Before we create the embedding, we need to specify the embedding size....\n",
    "- Two ways:  \n",
    "  - randomly pick a size\n",
    "    - min(50, unique/2)\n",
    "  - specify a size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the size of all my categorical cols\n",
    "cat_size = [len(df[col].cat.categories) for col in cat_cols]\n",
    "#[24, 2, 7]  #[24, 7, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 3)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = [(size, min(50, size//2)) for size in cat_size]\n",
    "emb_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Try to illustrate how Embedding layer works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = time[:1]\n",
    "sample\n",
    "twosamples = time[:2]\n",
    "twosamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected output after embedding of sample\n",
    "#[  [[12 numbers]], [[1 number]], [[3 numbers]]]\n",
    "\n",
    "#expected output after embedding of sample\n",
    "#[  [[12 numbers], [12 numbers]],   [[1 number], [1 number]], \n",
    "#   [[3 numbers], [3 numbers]]    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb_size: [(24, 12), (2, 1), (7, 3)]\n",
    "#but pyTorch does not have a list of nn.Embedding\n",
    "#if you want pyTorch to have a list of layers, use nn.ModuleList\n",
    "embed_layer = nn.ModuleList([nn.Embedding(unique, emb_s) for unique, emb_s in emb_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 3)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty embedding\n",
    "sample_embedding = []\n",
    "\n",
    "for i, e in enumerate(embed_layer):\n",
    "    sample_embedding.append(e(twosamples[:, i])) #apply embedding layer to column i\n",
    "                                                 #apply embedding layer 0 to column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.5210,  1.0202, -0.8309,  0.7269, -1.6530, -0.3662, -0.5252, -0.3393,\n",
       "           0.4639, -1.8913, -0.2017, -0.8986],\n",
       "         [-1.7746,  0.5431, -0.0365,  0.6595,  0.7031,  1.2418,  1.8766,  0.4441,\n",
       "          -0.0633,  0.5226,  0.9504,  2.4363]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[0.9013],\n",
       "         [0.9013]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-1.9770, -0.6194, -0.5559],\n",
       "         [ 0.6953, -1.1393, -1.6717]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5210,  1.0202, -0.8309,  0.7269, -1.6530, -0.3662, -0.5252, -0.3393,\n",
       "          0.4639, -1.8913, -0.2017, -0.8986,  0.9013, -1.9770, -0.6194, -0.5559],\n",
       "        [-1.7746,  0.5431, -0.0365,  0.6595,  0.7031,  1.2418,  1.8766,  0.4441,\n",
       "         -0.0633,  0.5226,  0.9504,  2.4363,  0.9013,  0.6953, -1.1393, -1.6717]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in coding, we want to concat all these embeddings, into one vector\n",
    "final_embedding = torch.cat(sample_embedding, 1)\n",
    "\n",
    "final_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gonna teach you very briefly about nn.Dropout\n",
    "#define a dropout layer\n",
    "dl = nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  2.0404, -0.0000,  0.0000, -0.0000, -0.0000, -1.0504, -0.0000,\n",
       "          0.9279, -3.7827, -0.4034, -1.7971,  0.0000, -3.9540, -1.2387, -0.0000],\n",
       "        [-3.5491,  1.0862, -0.0000,  0.0000,  0.0000,  2.4836,  3.7533,  0.0000,\n",
       "         -0.0000,  0.0000,  1.9008,  4.8727,  0.0000,  1.3906, -0.0000, -3.3434]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embedding = dl(final_embedding)\n",
    "final_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40.7305,  40.7447, -73.9924, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406,  40.7441, -73.9901, -73.9742,   1.0000,   1.3923]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cont = conts[:2]\n",
    "sample_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format: nn.BatchNorm1d(features)\n",
    "batch_norm1d = nn.BatchNorm1d(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8467,  0.0996, -0.3379, -0.1973,  0.0000,  1.0000],\n",
       "        [ 0.8457, -0.0996,  0.3418,  0.1953,  0.0000, -1.0000]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = batch_norm1d(sample_cont)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cat_embedding (120000, 16)\n",
    "#cont          (120000, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class someNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_size, cont_size, out_size, layer_size = [200, 100], p=0.5):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.ModuleList([nn.Embedding(unique, emb_s) for unique, emb_s in emb_size])\n",
    "        self.dropout     = nn.Dropout(p)\n",
    "        self.batchnorm1d = nn.BatchNorm1d(cont_size)\n",
    "        \n",
    "        #calculate input_size\n",
    "        cat_size = sum(emb_s for _, emb_s in emb_size)\n",
    "        input_size = cat_size + cont_size\n",
    "        \n",
    "        #linear(input_size, 200) -> relu -> batchnorm -> dropout\n",
    "        #linear(200, 100) -> relu -> batchnorm -> dropout\n",
    "        #linear(100, out_size)\n",
    "        layerlist = []\n",
    "        for i in layer_size:\n",
    "            layerlist.append(nn.Linear(input_size, i))  #(input_size, 200)\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "        layerlist.append(nn.Linear(layer_size[-1], out_size))\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "            \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        #x_cat:  (120000, 3)\n",
    "        #x_cont: (120000, 6)\n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.embed_layer):\n",
    "            embeddings.append(e(x_cat[:, i]))\n",
    "        x = torch.cat(embeddings, 1)  \n",
    "        #x: (120000, 16)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x_cont = self.batchnorm1d(x_cont)  \n",
    "        #x_cont: (120000, 6)\n",
    "        \n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        #x: (120000, 24)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = someNN(emb_size, conts.shape[1], len(y.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's test\n",
    "#random dataset\n",
    "sample_size = 3\n",
    "cat_size    = 3\n",
    "cont_size   = 6\n",
    "\n",
    "p = 0.5\n",
    "x_cat_hour  = torch.randint(0, 24,(sample_size, 1))\n",
    "x_cat_ampm  = torch.randint(0, 2, (sample_size, 1))\n",
    "x_cat_day   = torch.randint(0, 7, (sample_size, 1))\n",
    "x_cat_example      = torch.cat([x_cat_hour, x_cat_ampm, x_cat_day], 1)\n",
    "x_cont_example     = torch.randn(sample_size, cont_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  0,  5],\n",
       "        [10,  0,  2],\n",
       "        [19,  1,  1]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cat_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0369, -1.3148,  0.8313, -0.5515,  0.9075, -0.3025],\n",
       "        [ 1.8600,  0.3509,  0.4928,  0.1106,  0.3873, -1.2504],\n",
       "        [-1.5667, -0.7498,  0.5635,  1.0801,  1.0524,  0.7540]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cont_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x_cat, x_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5032,  0.5619],\n",
       "        [ 1.0589, -0.0125],\n",
       "        [-1.9812, -0.3272]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Training!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function \n",
    "J_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizer (you can try use Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "#Adam have dynamic learning schedules....\n",
    "#but it is NOT proven that Adam is better than SGD...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why you not use 120000, too lazy to wait\n",
    "#why you don't use dataloader, because our data is small, only 9 features....\n",
    "\n",
    "#train test split\n",
    "train_size = 60000\n",
    "test_size  = 12000\n",
    "\n",
    "#use your numpy indexing technique\n",
    "cat_train = time[:train_size]\n",
    "cat_test  = time[train_size:test_size+train_size]\n",
    "con_train = conts[:train_size]\n",
    "con_test  = conts[train_size:test_size+train_size]\n",
    "y_train   = y[:train_size]\n",
    "y_test    = y[train_size:test_size+train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5479730367660522\n",
      "Loss: 0.2863588333129883\n",
      "Loss: 0.27373749017715454\n",
      "Loss: 0.2667602300643921\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    yhat = model(cat_train, con_train)\n",
    "    loss = J_fn(yhat, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 25 == 1:\n",
    "        print(f\"Epoch: {i}; Loss: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = [loss.item() for loss in losses]\n",
    "# train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14413be50>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Testing/Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    yhat = model(cat_test, con_test)\n",
    "    loss = J_fn(yhat, y_test)\n",
    "    predicted = torch.max(yhat, 1)[1]\n",
    "    acc  = accuracy_score(predicted, y_test)\n",
    "    \n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
